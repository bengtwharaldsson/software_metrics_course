{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9d6f73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(filename='./information_quality.log', \n",
    "                    filemode='w',\n",
    "                    format='%(asctime)s;%(name)s;%(levelname)s;%(message)s',\n",
    "                    level=logging.DEBUG)\n",
    "\n",
    "logger = logging.getLogger('MI_defects')\n",
    "\n",
    "logger.info('Configuration started')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cda8d64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import requests\n",
    "    import os.path\n",
    "    import math\n",
    "    import time\n",
    "    import datetime\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    import yaml\n",
    "    from datetime import datetime, timedelta\n",
    "\n",
    "except Exception as e:\n",
    "    logger.error(f'Error importing modules: {e.msg}')\n",
    "\n",
    "logger.info('All modules imported successfully')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14c742cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with open(\"config.yaml\") as file:\n",
    "        config = yaml.safe_load(file)\n",
    "except Exception as e:\n",
    "    logger.error(f'Error loading configuration file: {e.msg}')\n",
    "\n",
    "try:\n",
    "    sources = config.get(\"defect_data_sources\")\n",
    "    selection = config.get(\"pick_defect_data_from\")\n",
    "    source = sources[selection]\n",
    "except Exception as e:\n",
    "    logger.error(f'Error accessing configuration values: {e.msg}')\n",
    "logger.info('Configuration loaded successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cfaf478c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading fresh data to data_gcc_180.csv\n",
      "Data download complete\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# get stuff from config\n",
    "url = source[\"url\"]\n",
    "product = source[\"product\"]\n",
    "#file_name = config.get(\"raw_defect_data\")\n",
    "days = config.get(\"get_defect_data_going_back_days\")\n",
    "\n",
    "# Function to download and cache data files to csv based on yaml config\n",
    "def get_raw_data(file_name, url, product, days):\n",
    "    # update url with search thing since no REST API available\n",
    "    data_url=url + \"/buglist.cgi\"\n",
    "\n",
    "    # Date window as an absolute date (safer than \"-Xd\" for some instances)\n",
    "    since = (datetime.utcnow() - timedelta(days=days)).strftime(\"%Y-%m-%d\")\n",
    "    \n",
    "    # Changed implementation to repeated tuples since I was only getting 1000 status NEW issues\n",
    "    # This works (thanks ChatGPT)\n",
    "    data_params = [\n",
    "        (\"product\", product),\n",
    "        (\"query_format\", \"advanced\"),\n",
    "        (\"bug_status\", \"NEW\"),\n",
    "        (\"bug_status\", \"ASSIGNED\"),\n",
    "        (\"bug_status\", \"REOPENED\"),\n",
    "        (\"bug_status\", \"RESOLVED\"),\n",
    "        (\"bug_status\", \"CLOSED\"),\n",
    "        (\"chfield\", \"[Bug creation]\"),\n",
    "        (\"chfieldfrom\", since),\n",
    "        (\"chfieldto\", \"Now\"),\n",
    "        (\"limit\", \"0\"),\n",
    "        (\"ctype\", \"csv\"),\n",
    "        (\"columnlist\", \"bug_id,product,component,assigned_to,bug_status,resolution,severity,bug_severity,opendate,changeddate\"),\n",
    "        (\"order\", \"bug_id DESC\"),\n",
    "    ]\n",
    "    print(\"Downloading fresh data to {}\".format(file_name))\n",
    "    try:\n",
    "        r = requests.get(data_url, params=data_params)\n",
    "        try:\n",
    "            with open(file_name, \"w\") as f:\n",
    "                f.write(r.text)\n",
    "        except Exception as e:\n",
    "            logger.error(f'Error writing raw data to file: {e.msg}')\n",
    "        logger.info('Raw data saved to file successfully')\n",
    "    except Exception as e:\n",
    "        logger.error(f'Error downloading raw data: {e.msg}')\n",
    "    logger.info('Raw data download complete')\n",
    "\n",
    "# Make raw data into pandas dataframe\n",
    "def get_data(bugzilla_url, product, days):\n",
    "    filename = \"data_{}_{}.csv\".format(product,days)\n",
    "    get_raw_data(filename, bugzilla_url, product, days)\n",
    "    print('Data download complete')\n",
    "    df = pd.read_csv(filename, header=0, parse_dates=[\"opendate\", \"changeddate\"])\n",
    "    return df\n",
    "\n",
    "RAW_DATA = get_data(url, product, days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d438f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of resolved issues: 1064\n",
      "Total number of issues: 1735\n",
      "Total number of resolved non-bugs: 50\n",
      "Curated data saved to base_measure_bugs_gcc_180.csv\n",
      "Curated data saved to base_measure_non_bugs_gcc_180.csv\n"
     ]
    }
   ],
   "source": [
    "# BASE MEASURES\n",
    "\n",
    "# Look in df to see the total number of resolved issues/entries\n",
    "base_measure_total_resolved_issues = len(RAW_DATA[(RAW_DATA[\"bug_status\"] == \"RESOLVED\") | (RAW_DATA[\"bug_status\"] == \"CLOSED\")])\n",
    "print(\"Total number of resolved issues:\", base_measure_total_resolved_issues)\n",
    "if base_measure_total_resolved_issues == 0:\n",
    "    logger.warning(\"No resolved issues found in the data!\")\n",
    "elif base_measure_total_resolved_issues < 0:\n",
    "    logger.error(\"Strange things going on. Count < 0: {}\".format(base_measure_total_resolved_issues))\n",
    "else:\n",
    "    logger.info(\"Total resolved issues OK.\")\n",
    "\n",
    "# Look in the df to see how many issues there are in total\n",
    "base_measure_total_issues = len(RAW_DATA)\n",
    "print(\"Total number of issues:\", base_measure_total_issues)\n",
    "if base_measure_total_issues == 0:\n",
    "    logger.warning(\"No issues found in the data!\")\n",
    "else:\n",
    "    logger.info(\"Total issues OK.\")\n",
    "\n",
    "# Look in the df to see how many of these issues were not bugs (i.e., enhancements)\n",
    "base_measure_total_resolved_non_bugs = len(RAW_DATA[((RAW_DATA[\"bug_status\"] == \"RESOLVED\") | (RAW_DATA[\"bug_status\"] == \"CLOSED\")) & (RAW_DATA[\"bug_severity\"]==\"enhancement\")])\n",
    "print(\"Total number of resolved non-bugs:\", base_measure_total_resolved_non_bugs)\n",
    "if base_measure_total_resolved_non_bugs == 0:\n",
    "    logger.warning(\"No resolved non-bugs found in the data!\")\n",
    "else:\n",
    "    logger.info(\"Total resolved non-bugs OK.\")\n",
    "\n",
    "# Save curated data for further analysis\n",
    "CURATED_DATA_FILE = \"base_measure_bugs_{}_{}.csv\".format(product,days)\n",
    "\n",
    "# Create df for base measures\n",
    "CURATED_DATA = RAW_DATA[((RAW_DATA[\"bug_status\"] == \"RESOLVED\") | (RAW_DATA[\"bug_status\"] == \"CLOSED\")) & (RAW_DATA[\"bug_severity\"]!=\"enhancement\")]\n",
    "CURATED_DATA.to_csv(CURATED_DATA_FILE, index=False)\n",
    "print(\"Curated data saved to {}\".format(CURATED_DATA_FILE))\n",
    "\n",
    "# Save curated data for further analysis\n",
    "CURATED_DATA_FILE = \"base_measure_non_bugs_{}_{}.csv\".format(product,days)\n",
    "\n",
    "# Create df for base measures\n",
    "CURATED_DATA = RAW_DATA[((RAW_DATA[\"bug_status\"] == \"RESOLVED\") | (RAW_DATA[\"bug_status\"] == \"CLOSED\")) & (RAW_DATA[\"bug_severity\"]==\"enhancement\")]\n",
    "CURATED_DATA.to_csv(CURATED_DATA_FILE, index=False)\n",
    "print(\"Curated data saved to {}\".format(CURATED_DATA_FILE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe2ce9d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resolution time data saved to resolution_time_gcc_180.csv\n"
     ]
    }
   ],
   "source": [
    "# function that returns a df with the resultion time per issue\n",
    "def get_resolution_time_df(df):\n",
    "    # Filter for resolved or closed issues\n",
    "    resolved_df = df[(df['bug_status'] == 'RESOLVED') | (df['bug_status'] == 'CLOSED')].copy()\n",
    "    if resolved_df.empty:\n",
    "        logger.warning(\"No resolved or closed issues found for resolution time calculation.\")\n",
    "    else:\n",
    "        logger.info(\"Resolved issues found for resolution time calculation.\")\n",
    "\n",
    "    # Calculate resolution time in days\n",
    "    resolved_df['resolution_time_days'] = (resolved_df['changeddate'] - resolved_df['opendate']).dt.total_seconds() / (24 * 3600)\n",
    "    if resolved_df['resolution_time_days'].isnull().all():\n",
    "        logger.warning(\"Resolution time calculation resulted in all NaN values.\")\n",
    "    elif (resolved_df['resolution_time_days'] < 0).any():\n",
    "        logger.error(\"Resolution time calculation resulted in negative values.\")\n",
    "    elif resolved_df['resolution_time_days'].isnull().sum() > 0:\n",
    "        logger.warning(\"Some resolution time values are NaN.\")\n",
    "    else:\n",
    "        logger.info(\"Resolution time calculation completed successfully.\")\n",
    "    \n",
    "    # Select relevant columns\n",
    "    try:\n",
    "        resolution_time_df = resolved_df[['bug_id', 'opendate', 'changeddate', 'resolution_time_days']]\n",
    "    except Exception as e:\n",
    "        logger.error(\"Error selecting relevant columns: {}\".format(e))\n",
    "        return None\n",
    "\n",
    "    return resolution_time_df\n",
    "\n",
    "RESOLUTION_TIME_DF = get_resolution_time_df(RAW_DATA)\n",
    "if RESOLUTION_TIME_DF is not None:\n",
    "    RESOLUTION_TIME_DF.to_csv(\"resolution_time_{}_{}.csv\".format(product,days), index=False)\n",
    "    print(\"Resolution time data saved to resolution_time_{}_{}.csv\".format(product,days))\n",
    "else:\n",
    "    logger.error(\"Resolution time DataFrame is None; skipping save operation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f0fad9a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average resolution time (days): 13.85676186995266\n"
     ]
    }
   ],
   "source": [
    "# DERIVED MEASURES\n",
    "\n",
    "# Function to calculate average resolution time\n",
    "def calculate_average_resolution_time(df):\n",
    "    try:\n",
    "        average_time = df['resolution_time_days'].mean()\n",
    "    except Exception as e:\n",
    "        logger.error(\"Error calculating average resolution time: {}\".format(e))\n",
    "        return None\n",
    "    return average_time\n",
    "average_resolution_time = calculate_average_resolution_time(RESOLUTION_TIME_DF)\n",
    "print(\"Average resolution time (days):\", average_resolution_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f331a478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction of unresolved non-bugs among unresolved issues: 0.15648286140089418\n",
      "Historical non-bug fraction - Mean: 0.091, Std: 0.117\n"
     ]
    }
   ],
   "source": [
    "# Function to calculate fraction of enhancements / other issues among unresolved issues per day\n",
    "def calculate_fraction_unresolved_non_bugs(df):\n",
    "    unresolved_df = df[~df['bug_status'].isin(['RESOLVED', 'CLOSED'])]\n",
    "    total_unresolved = unresolved_df.shape[0]\n",
    "    if total_unresolved == 0:\n",
    "        return 0.0\n",
    "    unresolved_non_bugs = unresolved_df[unresolved_df['bug_severity'] == 'enhancement'].shape[0]\n",
    "    try:\n",
    "        fraction = unresolved_non_bugs / total_unresolved\n",
    "    except ZeroDivisionError:\n",
    "        fraction = 0.0\n",
    "        logger.error(\"Division by zero when calculating fraction of unresolved non-bugs.\")\n",
    "    return fraction\n",
    "\n",
    "fraction_unresolved_non_bugs = calculate_fraction_unresolved_non_bugs(RAW_DATA)\n",
    "print(\"Fraction of unresolved non-bugs among unresolved issues:\", fraction_unresolved_non_bugs)\n",
    "\n",
    "# Function to calculate historical fraction of non-bugs over time\n",
    "def calculate_historical_non_bug_fraction(df):\n",
    "    # Group by date and calculate daily fraction\n",
    "    df_copy = df.copy()\n",
    "    df_copy['date'] = df_copy['opendate'].dt.date\n",
    "    \n",
    "    daily_fractions = []\n",
    "    for date in df_copy['date'].unique():\n",
    "        daily_issues = df_copy[df_copy['date'] == date]\n",
    "        total_daily = len(daily_issues)\n",
    "        non_bugs_daily = len(daily_issues[daily_issues['bug_severity'] == 'enhancement'])\n",
    "\n",
    "        try:\n",
    "            fraction = non_bugs_daily / total_daily\n",
    "        except ZeroDivisionError:\n",
    "            fraction = 0.0\n",
    "            logger.error(\"Division by zero when calculating historical non-bug fraction.\")\n",
    "\n",
    "        daily_fractions.append({'date': date, 'fraction_non_bugs': fraction})\n",
    "    \n",
    "    return pd.DataFrame(daily_fractions).sort_values('date')\n",
    "\n",
    "historical_fractions = calculate_historical_non_bug_fraction(RAW_DATA)\n",
    "print(f\"Historical non-bug fraction - Mean: {historical_fractions['fraction_non_bugs'].mean():.3f}, \"\n",
    "      f\"Std: {historical_fractions['fraction_non_bugs'].std():.3f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f4ffc68a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TRAFFIC LIGHT INDICATORS ===\n",
      "Current non-bug fraction: 0.156 (15.6%) → YELLOW\n",
      "\n",
      "Thresholds (for non-bug work):\n",
      "  GREEN: ≤ 10% non-bug work (focus on bug fixes)\n",
      "  YELLOW: 10% - 33% non-bug work (balanced workload)\n",
      "  RED: > 33% non-bug work (too much enhancement work)\n"
     ]
    }
   ],
   "source": [
    "# INDICATORS\n",
    "\n",
    "# Traffic light indicator based on YAML file settings for fraction of non-bug / bug work\n",
    "def traffic_light_indicator(value, thresholds):\n",
    "    \"\"\"\n",
    "    Returns traffic light color based on non-bug fraction thresholds\n",
    "    GREEN: Low non-bug fraction (≤ 10% - mostly bug fixes, good!)\n",
    "    YELLOW: Moderate non-bug fraction (10-33% - balanced workload)\n",
    "    RED: High non-bug fraction (> 33% - too much enhancement work, focus on bugs!)\n",
    "    \"\"\"\n",
    "    if value <= thresholds['green']:\n",
    "        return 'GREEN'\n",
    "    elif value <= thresholds['yellow']:\n",
    "        return 'YELLOW'\n",
    "    else:\n",
    "        return 'RED'\n",
    "\n",
    "# Get thresholds from config\n",
    "thresholds = config['indicators']['non_bug_fraction']\n",
    "\n",
    "# Calculate indicators\n",
    "current_indicator = traffic_light_indicator(fraction_unresolved_non_bugs, thresholds)\n",
    "\n",
    "\n",
    "# Display results\n",
    "print(\"=== TRAFFIC LIGHT INDICATORS ===\")\n",
    "print(f\"Current non-bug fraction: {fraction_unresolved_non_bugs:.3f} ({fraction_unresolved_non_bugs*100:.1f}%) → {current_indicator}\")\n",
    "\n",
    "print(f\"\\nThresholds (for non-bug work):\")\n",
    "print(f\"  GREEN: ≤ {thresholds['green']*100:.0f}% non-bug work (focus on bug fixes)\")\n",
    "print(f\"  YELLOW: {thresholds['green']*100:.0f}% - {thresholds['yellow']*100:.0f}% non-bug work (balanced workload)\")\n",
    "print(f\"  RED: > {thresholds['yellow']*100:.0f}% non-bug work (too much enhancement work)\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
